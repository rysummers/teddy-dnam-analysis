---
title: "T1D - Teddy Project"
author: "Ryan Summers"
date: "2026-01-06"
output:
  word_document: default
  pdf_document: default
  html_document:
    css: style.css
bibliography: t1d.bib
csl: "apa-5th-edition.csl"
nocite: '@*'
---

```{r setup, include=FALSE}
library(BiocManager)
library(knitr)
library(ggplot2)
library(tidyverse)
library(magrittr)
library(ggfortify)
library(olsrr)
library(kableExtra)
library(doBy)
library(MASS)
library(dplyr)
library(table1)
library(gtsummary)
library(gt)
library(stringdist)
library(ggrepel)
library(pwr)
library(ssize)
library(samr)
#library(simpleaffy)
library(parallel)
library(BiocParallel)
library(impute)
library(limma)
library(qvalue)
library(gtools)
library(multtest)
library(GEOquery)
library(Biobase)
library(data.table)
library(SummarizedExperiment)
library(variancePartition)
#library(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)
#library(IlluminaHumanMethylationEPICv2anno.20a1.hg38)
library(minfi)
library(R.utils)
library(stringr)
#library(IlluminaHumanMethylationEPICmanifest)
library(methylKit)
library(shinyMethyl)
library(minfi)
library(bumphunter)
#library(IlluminaHumanMethylation450kmanifest)
#library(IlluminaHumanMethylation450kanno.ilmn12.hg19)
library(qs)
library(qs2)
library(lme4)
library(sesame)
library(sva)
library(EmpiricalBrownsMethod)
#library(TxDb.Hsapiens.UCSC.hg19.knownGene)
#library(org.Hs.eg.db)
library(clusterProfiler)
library(patchwork)
library(ggmanh)
library(survival)
library(lme4)
library(SummarizedExperiment)
library(variancePartition)
library(lmerTest)
library(future.apply)
library(data.table)
```

Scripts for installing multiple packages
```{r}
# quick installation script
BiocManager::install(c(
  "SummarizedExperiment",
  "BiocParallel",
  "variancePartition"))

install.packages(c(
  "", ""))
```

Prior analyses reference code
```{r}
# TEMP for local testing
# setwd(paste0(Sys.getenv("RKJCOLLAB"), "/Maternal_Protection"))
# matrix_path <- "data/teddy/TEDDYarrays/preprocessing-dnam/mSet-norm-batch-mean-plate-row.Rdata"
# sample_ids_path <- "data/teddy/TEDDYarrays/samples-for-analysis.csv"
# pheno_path <- "data/teddy/TEDDYarrays/preprocessing-dnam/phenoData_v2.csv"
# model_path <- "/Users/slacksa/repos/explore_matprot/TEDDYcode/2-analysis/Functions/getSubSpecificInt_randomIntAndSlopeModel.R"
# # model_path <- "/Users/slacksa/repos/explore_matprot/TEDDYcode/2-analysis/Functions/getSubSpecificInt_randomIntModel.R"
# cell_types_path <- "data/teddy/TEDDYarrays/cell proportions/cell_counts_rescaled.csv"
# cov_list <- "factor(gender),new_CD8T,new_CD4T,new_NK,new_Bcell,new_Mono"
# # cov_list <- "factor(gender)"
# cov_list <- unlist(strsplit(cov_list, ","))
```


```{r}
# # load in M-value matrix
# M_read <- load("/Volumes/Storage/Maternal_Protection/data/teddy/TEDDYarrays/preprocessing-dnam/mSet-norm-batch-mean-plate-row.Rdata")
# 
# # save file using serialization - quicker
# qsave(mSet.norm.mean.plate_row, "/Volumes/Storage/Maternal_Protection/data/teddy/TEDDYarrays/preprocessing-dnam/M.matrix.qs", preset = "fast", nthreads = 6)
```

Loads data from personal external drive
```{r}
# load in qs file
M.matrix <- qread("/Volumes/Storage/Maternal_Protection/data/teddy/TEDDYarrays/preprocessing-dnam/M.matrix.qs", nthreads = 8)

qsave(M.matrix, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/raw/M.matrix.qs", nthreads = 6)
```


```{r}
# read in phenotype
pheno <- read.csv("/Volumes/Storage/Maternal_Protection/data/teddy/TEDDYarrays/preprocessing-dnam/phenoData_v2.csv")
```


```{r}
# Load list of IDs to keep in analysis
sample_ids_df <- read.csv("/Volumes/Storage/Maternal_Protection/data/teddy/TEDDYarrays/samples-for-analysis.csv")
sample_ids <- sample_ids_df$rgName
```


```{r}
# Load cell type proportions
cell_types <- read.csv("/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/cell_counts_rescaled.csv")
```


```{r}
# Filter matrix to just samples for analysis
matrix.filt <- M.matrix[, which(colnames(M.matrix) %in% sample_ids)]

# save matrix file to local
qsave(matrix.filt, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/matrix.filt.qs", nthreads = 6)
```

```{r}
# load matrix
matrix.filt <- qread("/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/matrix.filt.qs", nthreads = 6)

# save into new qs2 package
qs_save(matrix.filt, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/matrix.filt.qs2",
        nthreads = 6)
```

```{r}
# Rename pheno to match function code & filter to just samples want in analysis
pheno_filt <- pheno %>%
  dplyr::filter(rgName %in% sample_ids)
```

```{r}
# Add cell types to pheno
  # TO NOTE: model should include all cell types except for neutrophils, doing
  # this essentially sets neutrophils as reference
pheno_filt_ct <- left_join(pheno_filt, cell_types,
                           by = c("Sample_Name" = "samplemaskid"))

# convert to years and center to help with different scale issue when modeling
pheno_filt_ct$age_yrs_c <-
  (pheno_filt_ct$sample_agedys / 365.25) -
  mean(pheno_filt_ct$sample_agedys / 365.25)

# scale the cell covariates
covars <- c("new_Bcell", "new_CD4T", "new_CD8T",
            "new_Mono", "new_NK")

pheno_filt_ct[covars] <- scale(pheno_filt_ct[covars])

# save to csv
write.csv(pheno_filt_ct, file = "/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/pheno_scaled.csv")
qsave(pheno_filt_ct, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/pheno_filt_ct.qs", nthreads = 6)
```


```{r}
# load in pheno file 
pheno_filt_ct <- qread("/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/pheno_filt_ct.qs", nthreads = 6)
```

```{r}
# load in pheno scaled file 
pheno_filt_ct <- read_csv("/Users/ryan_summers/GitHub/teddy-dnam-analysis/data/processed/pheno_scaled.csv")
```

```{r}
# convert needed variables to factors
pheno_filt_ct <- pheno_filt_ct %>% 
  mutate(across(c(maskid, cc, gender), as.factor))

```


```{r}
# number of patients
length(unique(pheno_filt_ct$maskid))
```


```{r}
# measurement stats
pheno_filt_ct %>% 
  group_by(maskid) %>%
  summarise(n_measurements = n()) -> mnts_per_id 

mnts_per_id %>%   
  summarise(avg = mean(n_measurements),
            min = min(n_measurements),
            med = median(n_measurements),
            max = max(n_measurements))

hist(mnts_per_id$n_measurements, breaks = 12, freq = FALSE)
```



## Sanity check: confirm 1:1 sets

```{r}
check_sets <- pheno_df %>%
  dplyr::distinct(case_ind, maskid, outcome, endpt_days) %>%
  group_by(case_ind) %>%
  summarise(
    n_ids = n_distinct(maskid),
    n_cases = sum(outcome == 1),
    n_ctrls = sum(outcome == 0),
    endpt_unique = n_distinct(endpt_days),
    .groups = "drop")

table(check_sets$n_ids)
table(check_sets$n_cases)
table(check_sets$endpt_unique)

bad_sets <- check_sets %>% 
  filter(n_ids != 2 | n_cases != 1 | endpt_unique != 1)
bad_sets

```



```{r}
# pick one CpG
probe1 <- rownames(matrix.filt)[6645]

res1 <- mod_function_fast(
  probe = "cg25271479",
  matrix = matrix.filt,
  pheno = pheno_filt_ct,
  sample_var = "rgName",   # <-- column names of matrix (rgName)
  id_var = "maskid",          
  age_var = "sample_agedys",  
  covs = c("gender", "cc"),   
  return_blups = FALSE)

res1
```
Eigenvalue: 
0.0345 - Substantial random-effects variability
5×10⁻⁹- Essentially zero variability

Interpretation:
There is strong subject-to-subject variability in one direction (intercept), and almost none in the other (slope-related direction).

* Eigenvalues > 0 → matrix is positive definite (good)
* Very small eigenvalues → one direction has almost no variance
*	≈ 0 eigenvalue → model is near-singular
	
	

	
```{r}
library(future.apply)
library(data.table)

future::plan(future::multicore, workers = 6)   # adjust workers
options(future.globals.maxSize = 25 * 1024^3)  # 25GB for globals
```

A wrapper that calls your single-CpG function

This is where the “parallelization outside” happens: we create a function that fits one CpG, and future_lapply runs many instances of it in parallel.

```{r}
# form <- ~ age_yrs_c + gender + cc + new_Bcell + new_CD4T + new_CD8T + 
# new_Mono + new_NK + (1 | maskid)
fit_cpg <- function(probe) {
  mod_function(
    probe = probe,
    matrix = matrix.filt,
    pheno = pheno_filt_ct,
    sample_var = "rgName",    
    id_var = "maskid",           
    age_var = "age_yrs_c",   
    covs = c("gender", "cc", "new_Bcell", "new_CD4T", 
             "new_CD8T", "new_Mono", "new_NK"),    
    return_blups = FALSE # keep FALSE for speed
  )}

```

	
	
Run a small parallel test first	
```{r}
future::plan(future::multicore, workers = 6)
future::plan()
options(future.globals.maxSize = 20 * 1024^3)  # 20 GiBb

system.time({
  test_probes <- rownames(matrix.sample) # dim = 790944x1407
  test_res <- future_lapply(test_probes, fit_cpg)
  test_res <- data.table::rbindlist(test_res, fill = TRUE)
  })

# save to csv
write.csv(test_res, file = "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/test_res.csv")

# load csv
test_res <- read_csv("/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/test_res.csv")
```
    user   system  elapsed 
8063.489   73.480 8139.559 - 2.3hrs 

Estimated time to run all CpGs on my system:
20*8139.559 = 162791.2sec ≈ 2,714min ≈ 45.2hrs ≈ 2days


```{r}
# % of convergence issues based on 5% sample of 790,944 CpG sites
sum(!is.na(test_res$error_message)) / nrow(test_res) # 3.2%
```

```{r}
# extract errors from test run
error_cpgs <- test_res[test_res$fit_status == "error", "CpG"]$CpG

tt[error_cpgs,]
```


Methylation Values to Beta function
```{r}
m2beta <- function(m) {
  2^m / (1 + 2^m)}
```
	

## DREAM function analysis

```{r}
# now fit new summarized experiment object w/ filtered CpGs
pheno_ordered <- pheno_filt_ct[match(colnames(matrix.filt), pheno_filt_ct$rgName), ]
stopifnot(all(!is.na(pheno_ordered$rgName)))

# test a small sample
set.seed(2522)
idx <- sample(nrow(matrix.filt), 5000)
matrix.sample <- matrix.filt[idx, , drop = F]

pheno_ordered <- pheno_filt_ct[match(colnames(matrix.sample), 
                                     pheno_filt_ct$rgName), ]
stopifnot(all(!is.na(pheno_ordered$rgName)))

# build the SummarizedExperiment
se.filt <- SummarizedExperiment(
  assays = list(Mvalue = matrix.sample), #[1:39548,]
  colData = as.data.frame(pheno_ordered))

```


```{r}
# formula
form <- ~ age_yrs_c + gender + cc + new_Bcell + new_CD4T + new_CD8T + new_Mono + new_NK + (1 | maskid)
```

```{r}
# set up parallelization
n.cores <- parallel::detectCores() - 1
param <- SnowParam(5, type = "SOCK", progressbar = T)  
param <- MulticoreParam(workers = 5, progressbar = T)
```

```{r}
# fit the model - uses REML by default
system.time({
  dream.model3 <- suppressWarnings(
    dream(exprObj = assay(se.filt, "Mvalue"), 
          formula = form, 
          data = colData(se.filt), 
          ddf = "Satterthwaite", 
          BPPARAM = param))
  })

qsave(dream.model3, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/dream.model3.qs", preset = "fast", nthreads = 6)
```
user   system  elapsed 
39.413   10.947 1176.774 - 19.6min

Est full:
≈ 392min ≈ 6.5hrs - 6.9x faster than custom function


```{r}
dream_test3 <- topTable(dream.model3, number = Inf)

# number of significant CpGs based on adjusted p-value
nrow(subset(dream_test3, adj.P.Val < 0.05))
nrow(subset(dream_test3, adj.P.Val < 0.05)) / nrow(matrix.sample)
```




Alpine ≈ 319.96min ≈ 5.3hrs
```{r}
# load Alpine dream model
dream.model <- qs_read("/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/dream.model.qs2",
        nthreads = 6)
```


```{r}
# use topTable to view results
dream_res <- topTable(dream.model, number = Inf)

# save by serialization
qsave(dream_res, "dream_res.qs", nthreads=6)

# write to csv
write.csv(dream_res, file = "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/dream_res.csv")

# number of significant CpGs after
nrow(subset(dream_res, adj.P.Val < 0.05))

tt_T1DAge <- topTable(dream.model, coef = "diseaseCase:age_years",
         number = Inf, sort.by = "B") 

sig_tt <- topTable(dream.model, coef = "diseaseCase:age_years",
         number = Inf, sort.by = "B") 
```


## Model Diagnostics

```{r}
all_cpgs    <- rownames(matrix.filt)
modeled_cpgs <- rownames(dream.model)

# how many CpGs were dropped from model
length(setdiff(all_cpgs, modeled_cpgs))

# determine CpGs dropped from dream model
dropped <- setdiff(all_cpgs, modeled_cpgs)

# check variability of dropped CpGs
summary(apply(matrix.filt[dropped, ], 1, var))

```


```{r}
# number of significant CpGs based on adjusted p-value
nrow(subset(dream_res, adj.P.Val < 0.05))
nrow(subset(dream_res, adj.P.Val < 0.05)) / nrow(matrix.filt)

nrow(subset(test_res, p_slope < 0.05))
nrow(subset(test_res, p_slope < 0.05)) / nrow(test_res)

```

Check how many subjects only have one observation, which can be ill-posed for
random intercept/slope models
```{r}
pheno_filt_ct$maskid <- factor(pheno_filt_ct$maskid)
table_sizes <- table(pheno_filt_ct$maskid)
summary(table_sizes)
mean(table_sizes == 1)

```

Look at effect sizes

* logFC is the estimated regression coefficient = M-values
* AveExpr is the average level of M-values for CpG site across all samples
```{r}
tt <- topTable(dream.model2, coef="age_yrs_c", number=Inf)
summary(round(m2beta(abs(tt$logFC)), 4))  # for methylation, interpret appropriately
quantile(round(m2beta(abs(tt$logFC)),4), c(.5,.9,.99))

```

```{r}
# genomic inflation factor
chisq <- qchisq(1 - p, df=1)
lambda <- median(chisq, na.rm=TRUE) / qchisq(0.5, df=1)
lambda

```



```{r}
# Empirical Bayes - pulls info across all CpGs (stabilizes variances) 
dream.model.EB <- eBayes(dream.model)

# qs methods - soon to be deprecated
qsave(dream.model.EB, "dream.model.EB.qs", preset = "fast", nthreads = 6)


# load dream object
system.time({
  dream.model.EB <- qread("dream.model.EB.qs", nthreads = 8)
  })


```


Using Kenwood-Rogers to compare computational time an estimates

```{r}
# fit the model - uses REML by default
system.time({
  dream.model.KR <- suppressWarnings(
    dream(exprObj = assay(se.filt, "Mvalue"), 
          formula = form, 
          data = colData(se.filt), 
          ddf = "Kenward-Roger", 
          BPPARAM = param))
  })

qsave(dream.model.KR, "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/dream.model.KR.qs", preset = "fast", nthreads = 6)
```
    user   system  elapsed 
7136.401   72.690 1229.091 ~ 20.5min


```{r}
# save to csv
dream_test_res.KR <- topTable(dream.model.KR, number = Inf)
write.csv(dream_test_res.KR, file = "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/dream_test_res.KR.csv")
```

```{r}
nrow(subset(dream_test_res.KR, adj.P.Val < 0.05)) / nrow(matrix.filt[1:39548,])
```



## Test singularity issues from Dream for CpGs that gave issues in nlme pipeline

```{r}
# identify CpGs that didnt converge
# CpGs that threw an nlme error
bad_cpgs <- unique(test_res$CpG[!is.na(test_res$error_message)])

length(bad_cpgs)
head(bad_cpgs)

all_cpgs <- rownames(assay(se.filt, "Mvalue"))
bad_cpgs <- intersect(bad_cpgs, all_cpgs)

length(bad_cpgs)


```



```{r}

cpgs <- bad_cpgs

# 1) Precompute formula ONCE
form_cpg <- update(form, CpG ~ .)

# 2) Keep only columns used by the formula (big speed win)
vars_needed <- setdiff(all.vars(form_cpg), "CpG")
base_dat <- as.data.frame(colData(se.filt)[, vars_needed, drop = FALSE])

# 3) Pull the response matrix ONCE
Y <- assay(se.filt, "Mvalue")[cpgs, , drop = FALSE]

# 4) Chunk work to reduce Snow overhead
chunk_size <- 50
idx <- split(seq_along(cpgs), ceiling(seq_along(cpgs) / chunk_size))

res_list <- unlist(
  bplapply(
    idx,
    function(ii, Y, base_dat, form_cpg) {
      out <- vector("list", length(ii))
      for (k in seq_along(ii)) {
        i <- ii[k]
        dat <- base_dat
        dat$CpG <- as.numeric(Y[i, ])

        m <- tryCatch(
          suppressWarnings(
            lmer(form_cpg, data = dat, REML = TRUE)
            ),
          error = function(e) NULL
          )

        if (is.null(m)) {
          out[[k]] <- list(is_sing = NA, conv_msg = "lmer error")
        } else {
          msg <- m@optinfo$conv$lme4$messages
          out[[k]] <- list(
            is_sing  = lme4::isSingular(m, tol = 1e-4),
            conv_msg = if (length(msg)) paste(unlist(msg), collapse = " | ") else ""
          )
        }
      }
      out
    },
    Y = Y, base_dat = base_dat, form_cpg = form_cpg,
    BPPARAM = param
  ),
  recursive = FALSE
)

is_sing  <- vapply(res_list, `[[`, logical(1), "is_sing")
conv_msg <- vapply(res_list, `[[`, character(1), "conv_msg")

sing_df <- data.frame(CpG = cpgs, 
                      is_singular = is_sing, 
                      lmer_messages = conv_msg)

table(sing_df$is_singular, useNA = "ifany")

# write to csv
write.csv(sing_df, file = "/Users/ryan_summers/GitHub/teddy-dnam-analysis/results/sing_df.csv")
```


```{r}
sing_df <- data.frame(
  CpG = cpgs,
  is_singular = vapply(res_list, `[[`, logical(1), "is_sing"),
  lmer_messages = vapply(res_list, `[[`, character(1), "conv_msg"),
  stringsAsFactors = FALSE
)

table(sing_df$is_singular, useNA = "ifany")
head(subset(sing_df, is_singular))


```

“For each CpG we attempted a random-slope model. When fits were singular or showed convergence issues, we refit using a reduced random-effects structure (uncorrelated slope or random-intercept only). CpGs were excluded only if the reduced model failed or had insufficient observations.”





```{r}
cg25271479_df <- colData(se.filt) %>% 
  as.data.frame() %>%
  mutate(methylation = assay(se.filt, "Mvalue")["cg25271479", ])

## There is no exact, universally accepted denominator df because FE estimates
## depend on RE str and var components
## Therefore, lmer() omits p-values because df are ambiguous; in practice, lmerTest (Satterthwaite) is the standard way to obtain them, especially for large-scale longitudinal omics analyses.
cg25271479.lmer.model <- lmer(
  methylation ~ sample_agedys + gender + cc + (sample_agedys | maskid),
  data = cg25271479_df)

summary(cg25271479.lmer.model)

## The REML likelihood depends on the fixed‐effects design matrix
## REML integrates out fixed effects
## If you compare models with different fixed effects, the REML likelihoods are not comparable
ranova(cg25271479.lmer.model)

```

```{r}
isSingular(cg25271479.lmer.model, tol = getSingTol())
getSingTol()
```

How to see what is singular in your model
```{r}
VarCorr(cg25271479.lmer.model)
```


```{r}
cg25271479.lme.model <- lme(
  methylation ~ sample_agedys + gender + cc ,
  random = ~ sample_agedys | maskid,
  data = cg25271479_df)

summary(cg25271479.lme.model)
```





